{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DwxZR83oztgf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assumptions as per post 519:\n",
    "# 1) conlleval.py present in the directory\n",
    "# 2) glove.6B.100d.txt present in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "W1sjPqBk2n9R",
    "outputId": "ad7c26a2-62b7-4dc5-f90e-d76844256d77",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio\n",
    "!pip install numpy\n",
    "!pip install -q datasets\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Dxqfl_FfpWZt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OpX8FieC26wn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam, AdamW\n",
    "import numpy as np\n",
    "from conlleval import evaluate\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_mJHt7bT9Dvt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5oQCiPD63lMM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = datasets.load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "C8b6G5vD3p76",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculating the word frequency\n",
    "word_frequency = Counter(itertools.chain(*dataset['train']['tokens']))\n",
    "# Creating a dictionary with words having frequency greater than 2\n",
    "word_frequency = {\n",
    "    word: frequency\n",
    "    for word, frequency in word_frequency.items()\n",
    "    if frequency >= 3\n",
    "}\n",
    "\n",
    "# Adding the index and UNK and PAD to handle padding and unknown tokens:\n",
    "word2idx = {\n",
    "    word: index\n",
    "    for index, word in enumerate(word_frequency.keys(), start=2)\n",
    "}\n",
    "word2idx['[PAD]'] = 0\n",
    "word2idx['[UNK]'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "df4b36222d7d424e84e9adad82b0f6ed",
      "f9aa6aa549124b5598da4fca2e798697",
      "a99cd51a140b44a4b12504f499a613ed",
      "5ceaeda57cd44bc88ed7dd3a8329b496",
      "687ee4a211fb402fb18b4e595fb62ee6",
      "ae685b5f2b8d4c538fba0f980ccb03de",
      "86792eac34d24a57833702df5d7c38ff",
      "21032812faeb4317b18a213800270eed",
      "10d5d9421b65412ea1312cfcea61d5d5",
      "6410529f8ecc4d7ab7523c4dd2d8e696",
      "d74fd57600da41438a2ff864c734657c",
      "c26b46d9e06e48bf89ba3d41e2793051",
      "f3a8a0c823284a628bf7c95f857faefa",
      "3295795b0ab546c9a44ddbed27b70907",
      "4b3594287e404655b6bf85435d061864",
      "d74f25d35ab442d19d86f8e231703191",
      "ddc86aa121554a6ebb65d638091f8ee9",
      "4dc9b24267224f628940fbf62cb4a91b",
      "1b27335e9d9548c88b53c22803b5652a",
      "6a97dc65a24c4519ba1a006881c38b91",
      "67fca6992c864f58b7ef7bfd9b53959e",
      "55fcb1b0cbd04b999a25d98f9bf185da",
      "346a5410b8c944418aa8a4b07aa7dbb5",
      "403685c606ed427d84a673744fb2eb01",
      "949a61f3b5894861b0551d2bed787c22",
      "a1a094aef5b345168eeb0fa248d3e7d1",
      "722fa30a89ab4746903a933835575d5a",
      "bf1094b3c35a48109bcae6ccb349485f",
      "7d80c0ba38094591b2afa75946208302",
      "77d6aead62bc48fea068aefd1df44ad6",
      "22c79e18d7c74dcd8379aa5f0129bede",
      "85d16c16b71342c6ac06d8105a414490",
      "5a5524c1d44c472184239b0ec74d69f0"
     ]
    },
    "id": "6uOEj07b3vct",
    "outputId": "377f20f9-05b5-4e2e-f9c9-7807a23157e2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4b36222d7d424e84e9adad82b0f6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26b46d9e06e48bf89ba3d41e2793051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346a5410b8c944418aa8a4b07aa7dbb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iterating the dataset to replace unknown tokens with [UNK]\n",
    "dataset = (\n",
    "    dataset\n",
    "    .map(lambda x: {\n",
    "            'input_ids': [\n",
    "                word2idx.get(word, word2idx['[UNK]'])\n",
    "                for word in x['tokens']\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9icKYbh4iO5",
    "outputId": "53dfd865-4107-4959-c8ea-f043e8ece7a6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ReRsEbjs4j3n",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Removing columns pos_tags & chunk_tags; Renaming column ner_tags to labels\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(['pos_tags', 'chunk_tags'])\n",
    "    dataset[split] = dataset[split].rename_column('ner_tags', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UktmNJv15Dhv",
    "outputId": "1d2d1d45-126f-4777-a417-175806781905",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8128\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2idx)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hk5LwDol74nM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NER tag mapping\n",
    "ner_tags = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8, '[PAD]': 9}\n",
    "idx2tag = {idx: tag for tag, idx in ner_tags.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdXl0wGqApUn"
   },
   "source": [
    "**Task 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KIt1YJLD4366",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model Architecture:\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, lstm_hidden_dim, output_dim):\n",
    "        dropout_val = 0.33\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.bilstm = nn.LSTM(embedding_dim, lstm_hidden_dim, num_layers = 1, bidirectional=True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_val)\n",
    "        self.linear = nn.Linear(lstm_hidden_dim*2, output_dim)\n",
    "        self.elu = nn.ELU()\n",
    "        self.classifier = nn.Linear(output_dim, len(ner_tags)-1)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        embed = self.embedding(x)\n",
    "        lstm_out, _ = self.bilstm(embed)\n",
    "        drop = self.dropout(lstm_out)\n",
    "        linear = self.linear(drop)\n",
    "        elu_out = self.elu(linear)\n",
    "        logits = self.classifier(elu_out)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            logits_flatten = logits.view(-1, logits.shape[-1])\n",
    "            labels_flatten = labels.view(-1)\n",
    "            loss = nn.functional.cross_entropy(logits_flatten, labels_flatten,ignore_index=9)\n",
    "\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "EWMWbXhW8S_P",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "validation_data = dataset['validation']\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "l3ZV--iP8Wab",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def collate_fun(batch):\n",
    "\n",
    "    input_ids = [torch.tensor(item['input_ids'], device=device) for item in batch]\n",
    "    labels = [torch.tensor(item['labels'], device=device) for item in batch]\n",
    "    lengths = [len(label) for label in labels]\n",
    "\n",
    "    input_ids_padded = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "    labels_padded = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=9)\n",
    "    return {'input_ids': input_ids_padded, 'labels': labels_padded, 'lengths': lengths}\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size= batch_size, collate_fn = collate_fun)\n",
    "test_loader = DataLoader(test_data, batch_size= batch_size, collate_fn = collate_fun)\n",
    "validation_loader = DataLoader(validation_data, batch_size= batch_size, collate_fn = collate_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "X956hzTf93dn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = BiLSTM(vocab_size=vocab_size, embedding_dim=100, lstm_hidden_dim=256, output_dim=128).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=0.001)\n",
    "best_val_f1 = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GLVZTkUK9L45",
    "outputId": "b5f2347a-ded2-44f0-9c09-336aea38e5a1",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51362 tokens with 5942 phrases; found: 3177 phrases; correct: 1923.\n",
      "accuracy:  34.77%; (non-O)\n",
      "accuracy:  88.70%; precision:  60.53%; recall:  32.36%; FB1:  42.18\n",
      "              LOC: precision:  72.06%; recall:  49.70%; FB1:  58.83  1267\n",
      "             MISC: precision:  53.37%; recall:  10.30%; FB1:  17.27  178\n",
      "              ORG: precision:  41.58%; recall:  30.20%; FB1:  34.99  974\n",
      "              PER: precision:  67.28%; recall:  27.69%; FB1:  39.23  758\n",
      "Epoch: 0, Train Loss: 0.6636327108991988\n",
      "Epoch: 0, Validation Loss: 0.3902442083493167\n",
      "Validation F1 increased (0.0000 --> 42.1757). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 4331 phrases; correct: 3154.\n",
      "accuracy:  56.18%; (non-O)\n",
      "accuracy:  92.38%; precision:  72.82%; recall:  53.08%; FB1:  61.40\n",
      "              LOC: precision:  83.06%; recall:  64.34%; FB1:  72.52  1423\n",
      "             MISC: precision:  78.18%; recall:  49.35%; FB1:  60.51  582\n",
      "              ORG: precision:  55.31%; recall:  48.92%; FB1:  51.92  1186\n",
      "              PER: precision:  75.53%; recall:  46.74%; FB1:  57.75  1140\n",
      "Epoch: 1, Train Loss: 0.3100220473538363\n",
      "Epoch: 1, Validation Loss: 0.24765182019887017\n",
      "Validation F1 increased (42.1757 --> 61.4037). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 4863 phrases; correct: 3754.\n",
      "accuracy:  66.30%; (non-O)\n",
      "accuracy:  94.01%; precision:  77.20%; recall:  63.18%; FB1:  69.49\n",
      "              LOC: precision:  86.17%; recall:  72.95%; FB1:  79.01  1555\n",
      "             MISC: precision:  81.93%; recall:  63.45%; FB1:  71.52  714\n",
      "              ORG: precision:  62.08%; recall:  59.58%; FB1:  60.81  1287\n",
      "              PER: precision:  78.81%; recall:  55.92%; FB1:  65.42  1307\n",
      "Epoch: 2, Train Loss: 0.1860341761454278\n",
      "Epoch: 2, Validation Loss: 0.1905136772057078\n",
      "Validation F1 increased (61.4037 --> 69.4863). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 5122 phrases; correct: 4067.\n",
      "accuracy:  71.37%; (non-O)\n",
      "accuracy:  94.85%; precision:  79.40%; recall:  68.44%; FB1:  73.52\n",
      "              LOC: precision:  87.19%; recall:  76.70%; FB1:  81.61  1616\n",
      "             MISC: precision:  81.10%; recall:  68.87%; FB1:  74.49  783\n",
      "              ORG: precision:  66.06%; recall:  64.43%; FB1:  65.23  1308\n",
      "              PER: precision:  81.91%; recall:  62.92%; FB1:  71.17  1415\n",
      "Epoch: 3, Train Loss: 0.12183876473940315\n",
      "Epoch: 3, Validation Loss: 0.16661824801178904\n",
      "Validation F1 increased (69.4863 --> 73.5177). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 5302 phrases; correct: 4242.\n",
      "accuracy:  74.44%; (non-O)\n",
      "accuracy:  95.18%; precision:  80.01%; recall:  71.39%; FB1:  75.45\n",
      "              LOC: precision:  87.99%; recall:  79.37%; FB1:  83.46  1657\n",
      "             MISC: precision:  83.94%; recall:  70.28%; FB1:  76.51  772\n",
      "              ORG: precision:  64.15%; recall:  67.26%; FB1:  65.67  1406\n",
      "              PER: precision:  84.12%; recall:  66.99%; FB1:  74.58  1467\n",
      "Epoch: 4, Train Loss: 0.08455812154207294\n",
      "Epoch: 4, Validation Loss: 0.16090877685814584\n",
      "Validation F1 increased (73.5177 --> 75.4536). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 5417 phrases; correct: 4383.\n",
      "accuracy:  76.65%; (non-O)\n",
      "accuracy:  95.51%; precision:  80.91%; recall:  73.76%; FB1:  77.17\n",
      "              LOC: precision:  90.48%; recall:  81.22%; FB1:  85.60  1649\n",
      "             MISC: precision:  81.27%; recall:  72.02%; FB1:  76.37  817\n",
      "              ORG: precision:  67.38%; recall:  68.23%; FB1:  67.80  1358\n",
      "              PER: precision:  82.36%; recall:  71.23%; FB1:  76.39  1593\n",
      "Epoch: 5, Train Loss: 0.05989609160797314\n",
      "Epoch: 5, Validation Loss: 0.15836506466582126\n",
      "Validation F1 increased (75.4536 --> 77.1723). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 5513 phrases; correct: 4379.\n",
      "accuracy:  76.86%; (non-O)\n",
      "accuracy:  95.45%; precision:  79.43%; recall:  73.70%; FB1:  76.46\n",
      "              LOC: precision:  88.29%; recall:  82.47%; FB1:  85.28  1716\n",
      "             MISC: precision:  79.31%; recall:  71.91%; FB1:  75.43  836\n",
      "              ORG: precision:  65.82%; recall:  67.64%; FB1:  66.72  1378\n",
      "              PER: precision:  81.74%; recall:  70.25%; FB1:  75.56  1583\n",
      "Epoch: 6, Train Loss: 0.04306901675829444\n",
      "Epoch: 6, Validation Loss: 0.16944996220049421\n",
      "processed 51362 tokens with 5942 phrases; found: 5440 phrases; correct: 4387.\n",
      "accuracy:  76.59%; (non-O)\n",
      "accuracy:  95.43%; precision:  80.64%; recall:  73.83%; FB1:  77.09\n",
      "              LOC: precision:  89.98%; recall:  81.65%; FB1:  85.62  1667\n",
      "             MISC: precision:  76.45%; recall:  72.89%; FB1:  74.63  879\n",
      "              ORG: precision:  68.05%; recall:  68.46%; FB1:  68.25  1349\n",
      "              PER: precision:  83.95%; recall:  70.41%; FB1:  76.59  1545\n",
      "Epoch: 7, Train Loss: 0.03227576900841451\n",
      "Epoch: 7, Validation Loss: 0.18479545962698324\n",
      "processed 51362 tokens with 5942 phrases; found: 5858 phrases; correct: 4471.\n",
      "accuracy:  78.14%; (non-O)\n",
      "accuracy:  95.15%; precision:  76.32%; recall:  75.24%; FB1:  75.78\n",
      "              LOC: precision:  85.12%; recall:  83.45%; FB1:  84.28  1801\n",
      "             MISC: precision:  70.13%; recall:  73.86%; FB1:  71.95  971\n",
      "              ORG: precision:  64.05%; recall:  70.54%; FB1:  67.14  1477\n",
      "              PER: precision:  81.48%; recall:  71.17%; FB1:  75.98  1609\n",
      "Epoch: 8, Train Loss: 0.026288396433106643\n",
      "Epoch: 8, Validation Loss: 0.18995527111110277\n",
      "processed 51362 tokens with 5942 phrases; found: 5640 phrases; correct: 4465.\n",
      "accuracy:  78.10%; (non-O)\n",
      "accuracy:  95.48%; precision:  79.17%; recall:  75.14%; FB1:  77.10\n",
      "              LOC: precision:  90.58%; recall:  82.14%; FB1:  86.15  1666\n",
      "             MISC: precision:  75.98%; recall:  73.43%; FB1:  74.68  891\n",
      "              ORG: precision:  66.48%; recall:  69.50%; FB1:  67.95  1402\n",
      "              PER: precision:  80.13%; recall:  73.13%; FB1:  76.47  1681\n",
      "Epoch: 9, Train Loss: 0.022471409347392786\n",
      "Epoch: 9, Validation Loss: 0.20204291901527363\n",
      "processed 51362 tokens with 5942 phrases; found: 5735 phrases; correct: 4506.\n",
      "accuracy:  78.94%; (non-O)\n",
      "accuracy:  95.46%; precision:  78.57%; recall:  75.83%; FB1:  77.18\n",
      "              LOC: precision:  87.10%; recall:  83.78%; FB1:  85.41  1767\n",
      "             MISC: precision:  77.94%; recall:  73.97%; FB1:  75.90  875\n",
      "              ORG: precision:  65.73%; recall:  69.95%; FB1:  67.77  1427\n",
      "              PER: precision:  80.85%; recall:  73.13%; FB1:  76.80  1666\n",
      "Epoch: 10, Train Loss: 0.018384253433334073\n",
      "Epoch: 10, Validation Loss: 0.212188676871615\n",
      "Validation F1 increased (77.1723 --> 77.1774). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 5761 phrases; correct: 4546.\n",
      "accuracy:  79.17%; (non-O)\n",
      "accuracy:  95.53%; precision:  78.91%; recall:  76.51%; FB1:  77.69\n",
      "              LOC: precision:  87.16%; recall:  83.89%; FB1:  85.49  1768\n",
      "             MISC: precision:  75.38%; recall:  74.40%; FB1:  74.89  910\n",
      "              ORG: precision:  68.48%; recall:  69.50%; FB1:  68.99  1361\n",
      "              PER: precision:  80.55%; recall:  75.30%; FB1:  77.83  1722\n",
      "Epoch: 11, Train Loss: 0.014689100629115945\n",
      "Epoch: 11, Validation Loss: 0.21830930830932915\n",
      "Validation F1 increased (77.1774 --> 77.6895). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 5637 phrases; correct: 4551.\n",
      "accuracy:  79.29%; (non-O)\n",
      "accuracy:  95.76%; precision:  80.73%; recall:  76.59%; FB1:  78.61\n",
      "              LOC: precision:  90.45%; recall:  82.47%; FB1:  86.28  1675\n",
      "             MISC: precision:  78.35%; recall:  75.38%; FB1:  76.84  887\n",
      "              ORG: precision:  72.94%; recall:  69.35%; FB1:  71.10  1275\n",
      "              PER: precision:  78.39%; recall:  76.60%; FB1:  77.48  1800\n",
      "Epoch: 12, Train Loss: 0.011818865107701793\n",
      "Epoch: 12, Validation Loss: 0.23496087240519223\n",
      "Validation F1 increased (77.6895 --> 78.6078). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 5656 phrases; correct: 4523.\n",
      "accuracy:  78.60%; (non-O)\n",
      "accuracy:  95.65%; precision:  79.97%; recall:  76.12%; FB1:  78.00\n",
      "              LOC: precision:  86.90%; recall:  84.10%; FB1:  85.48  1778\n",
      "             MISC: precision:  79.91%; recall:  73.75%; FB1:  76.71  851\n",
      "              ORG: precision:  70.02%; recall:  69.50%; FB1:  69.76  1331\n",
      "              PER: precision:  80.54%; recall:  74.16%; FB1:  77.22  1696\n",
      "Epoch: 13, Train Loss: 0.012203457638822074\n",
      "Epoch: 13, Validation Loss: 0.2450696681744197\n",
      "processed 51362 tokens with 5942 phrases; found: 5642 phrases; correct: 4537.\n",
      "accuracy:  78.68%; (non-O)\n",
      "accuracy:  95.77%; precision:  80.41%; recall:  76.35%; FB1:  78.33\n",
      "              LOC: precision:  86.56%; recall:  84.16%; FB1:  85.34  1786\n",
      "             MISC: precision:  81.09%; recall:  73.97%; FB1:  77.37  841\n",
      "              ORG: precision:  76.02%; recall:  66.89%; FB1:  71.16  1180\n",
      "              PER: precision:  76.95%; recall:  76.66%; FB1:  76.80  1835\n",
      "Epoch: 14, Train Loss: 0.011745665162984685\n",
      "Epoch: 14, Validation Loss: 0.2504376052004541\n",
      "processed 51362 tokens with 5942 phrases; found: 5655 phrases; correct: 4519.\n",
      "accuracy:  78.93%; (non-O)\n",
      "accuracy:  95.65%; precision:  79.91%; recall:  76.05%; FB1:  77.93\n",
      "              LOC: precision:  87.79%; recall:  83.72%; FB1:  85.71  1752\n",
      "             MISC: precision:  81.58%; recall:  73.97%; FB1:  77.59  836\n",
      "              ORG: precision:  71.22%; recall:  69.95%; FB1:  70.58  1317\n",
      "              PER: precision:  77.77%; recall:  73.89%; FB1:  75.78  1750\n",
      "Epoch: 15, Train Loss: 0.01050128613831782\n",
      "Epoch: 15, Validation Loss: 0.25423536887483705\n",
      "processed 51362 tokens with 5942 phrases; found: 5799 phrases; correct: 4610.\n",
      "accuracy:  79.97%; (non-O)\n",
      "accuracy:  95.71%; precision:  79.50%; recall:  77.58%; FB1:  78.53\n",
      "              LOC: precision:  87.12%; recall:  85.03%; FB1:  86.06  1793\n",
      "             MISC: precision:  84.77%; recall:  72.45%; FB1:  78.13  788\n",
      "              ORG: precision:  65.93%; recall:  71.59%; FB1:  68.64  1456\n",
      "              PER: precision:  80.59%; recall:  77.09%; FB1:  78.80  1762\n",
      "Epoch: 16, Train Loss: 0.009613973399300988\n",
      "Epoch: 16, Validation Loss: 0.24981880438637888\n",
      "processed 51362 tokens with 5942 phrases; found: 5584 phrases; correct: 4507.\n",
      "accuracy:  78.53%; (non-O)\n",
      "accuracy:  95.79%; precision:  80.71%; recall:  75.85%; FB1:  78.21\n",
      "              LOC: precision:  88.81%; recall:  82.53%; FB1:  85.55  1707\n",
      "             MISC: precision:  85.52%; recall:  74.30%; FB1:  79.51  801\n",
      "              ORG: precision:  72.38%; recall:  68.98%; FB1:  70.64  1278\n",
      "              PER: precision:  76.81%; recall:  74.97%; FB1:  75.88  1798\n",
      "Epoch: 17, Train Loss: 0.00844681326858555\n",
      "Epoch: 17, Validation Loss: 0.27087047008152176\n",
      "processed 51362 tokens with 5942 phrases; found: 5636 phrases; correct: 4557.\n",
      "accuracy:  79.36%; (non-O)\n",
      "accuracy:  95.83%; precision:  80.86%; recall:  76.69%; FB1:  78.72\n",
      "              LOC: precision:  88.59%; recall:  83.23%; FB1:  85.83  1726\n",
      "             MISC: precision:  86.92%; recall:  72.78%; FB1:  79.22  772\n",
      "              ORG: precision:  73.00%; recall:  69.95%; FB1:  71.44  1285\n",
      "              PER: precision:  76.58%; recall:  77.04%; FB1:  76.81  1853\n",
      "Epoch: 18, Train Loss: 0.007829904260111138\n",
      "Epoch: 18, Validation Loss: 0.28675997486991534\n",
      "Validation F1 increased (78.6078 --> 78.7183). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 5431 phrases; correct: 4481.\n",
      "accuracy:  78.07%; (non-O)\n",
      "accuracy:  95.85%; precision:  82.51%; recall:  75.41%; FB1:  78.80\n",
      "              LOC: precision:  90.90%; recall:  82.14%; FB1:  86.30  1660\n",
      "             MISC: precision:  83.31%; recall:  74.73%; FB1:  78.79  827\n",
      "              ORG: precision:  74.74%; recall:  69.50%; FB1:  72.02  1247\n",
      "              PER: precision:  79.61%; recall:  73.34%; FB1:  76.35  1697\n",
      "Epoch: 19, Train Loss: 0.007166095389616431\n",
      "Epoch: 19, Validation Loss: 0.2979401738826134\n",
      "Validation F1 increased (78.7183 --> 78.8007). Saving model...\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20  # Number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_f1 = 0\n",
    "    for data in train_loader:\n",
    "        input_ids, labels, lengths = data['input_ids'], data['labels'], data['lengths']\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        logits, loss = model(input_ids, labels)\n",
    "\n",
    "        if loss is not None:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=-1).view(-1)\n",
    "        labels_flat = labels.view(-1)\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss, valid_f1 = 0, 0\n",
    "    all_val_predictions, all_val_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in validation_loader:\n",
    "\n",
    "            input_ids, labels, lengths = data['input_ids'], data['labels'], data['lengths']\n",
    "            # print(input_ids, '\\n', '----------------------------', labels)\n",
    "            logits, loss = model(input_ids, labels)\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            val_predictions = torch.argmax(logits, dim=-1).tolist()\n",
    "\n",
    "            for i, length in enumerate(lengths):\n",
    "              seq_preds = val_predictions[i][:length]\n",
    "              seq_labels = labels[i, :length].tolist()\n",
    "              mapped_seq_preds = [idx2tag[p] for p in seq_preds]\n",
    "              mapped_seq_labels = [idx2tag[l] for l in seq_labels]\n",
    "\n",
    "              all_val_predictions.extend(mapped_seq_preds)\n",
    "              all_val_labels.extend(mapped_seq_labels)\n",
    "\n",
    "        flat_preds = list(itertools.chain(*all_val_predictions))\n",
    "        flat_labels = list(itertools.chain(*all_val_labels))\n",
    "        precision, recall, f1 = evaluate(all_val_labels, all_val_predictions)\n",
    "\n",
    "\n",
    "        print(f\"Epoch: {epoch}, Train Loss: {total_loss / len(train_loader)}\")\n",
    "        print(f\"Epoch: {epoch}, Validation Loss: {valid_loss / len(validation_loader)}\")\n",
    "\n",
    "        # Saving best model based on best F1 score\n",
    "        if f1 > best_val_f1:\n",
    "            print(f'Validation F1 increased ({best_val_f1:.4f} --> {f1:.4f}). Saving model...')\n",
    "            torch.save(model.state_dict(), 'model.pt')\n",
    "            best_val_f1 = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "veoc8Upu9n-g",
    "outputId": "27cd1a98-e74a-4b09-ba2b-6b5ec7821ef7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM(\n",
      "  (embedding): Embedding(8128, 100)\n",
      "  (bilstm): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.33, inplace=False)\n",
      "  (linear): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (elu): ELU(alpha=1.0)\n",
      "  (classifier): Linear(in_features=128, out_features=9, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model architechture:\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQ8OJEdHcpIq"
   },
   "source": [
    "Hyperparameters:\n",
    "\n",
    "1) Number Of Epochs: 20\n",
    "\n",
    "2) Optimizer: AdamW\n",
    "\n",
    "3) Learning rate: 0.001\n",
    "\n",
    "4) Best Model saved based on F1 score\n",
    "\n",
    "5) Dropout: 0.33\n",
    "\n",
    "6) Vocab size: 8128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pynQKa1ZA7kL"
   },
   "source": [
    "### **Results on Validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_QW4HLh_fxz",
    "outputId": "134134c8-c731-46c0-bfda-850cd282e085",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51362 tokens with 5942 phrases; found: 5431 phrases; correct: 4481.\n",
      "accuracy:  78.07%; (non-O)\n",
      "accuracy:  95.85%; precision:  82.51%; recall:  75.41%; FB1:  78.80\n",
      "              LOC: precision:  90.90%; recall:  82.14%; FB1:  86.30  1660\n",
      "             MISC: precision:  83.31%; recall:  74.73%; FB1:  78.79  827\n",
      "              ORG: precision:  74.74%; recall:  69.50%; FB1:  72.02  1247\n",
      "              PER: precision:  79.61%; recall:  73.34%; FB1:  76.35  1697\n",
      "Precision: 82.50782544651078\n",
      "Recall: 75.41231908448334\n",
      "F1 Score: 78.80066824936252\n"
     ]
    }
   ],
   "source": [
    "# Model on validation set\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "model.eval()\n",
    "preds = []\n",
    "label_list = []\n",
    "with torch.no_grad():\n",
    "    for data in validation_loader:\n",
    "        input_ids, labels, lengths = data['input_ids'], data['labels'], data['lengths']\n",
    "        logits, loss = model(input_ids, labels)\n",
    "        predictions = torch.argmax(logits, dim=2)\n",
    "\n",
    "        for pred, label, length in zip(predictions.tolist(), labels.tolist(), lengths):\n",
    "            decoded_label = [idx2tag[l] for l in label]\n",
    "            label_list.extend([decoded_label[:length]])\n",
    "            trimmed_pred = pred[:length]\n",
    "            decoded_pred = [idx2tag[p] for p in trimmed_pred]\n",
    "            preds.extend([decoded_pred])\n",
    "\n",
    "flat_preds = list(itertools.chain(*preds))\n",
    "flat_labels = list(itertools.chain(*label_list))\n",
    "precision, recall, f1 = evaluate(flat_labels, flat_preds)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "01yeXeZab49v",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What are the precision, recall, and F1 score on the validation data?.\n",
    "# precision:  82.51%; recall:  75.41%; FB1:  78.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sOmR6lKAwr8"
   },
   "source": [
    "### **Results on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3ddQovH_vpV",
    "outputId": "ae872b0f-2d70-4045-d464-1325e5099731",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 46435 tokens with 5648 phrases; found: 4981 phrases; correct: 3709.\n",
      "accuracy:  70.38%; (non-O)\n",
      "accuracy:  93.86%; precision:  74.46%; recall:  65.67%; FB1:  69.79\n",
      "              LOC: precision:  85.47%; recall:  74.04%; FB1:  79.34  1445\n",
      "             MISC: precision:  65.77%; recall:  62.68%; FB1:  64.19  669\n",
      "              ORG: precision:  70.23%; recall:  59.66%; FB1:  64.52  1411\n",
      "              PER: precision:  71.63%; recall:  64.50%; FB1:  67.88  1456\n",
      "Precision: 74.4629592451315\n",
      "Recall: 65.66926345609065\n",
      "F1 Score: 69.79019663185625\n"
     ]
    }
   ],
   "source": [
    "# Model on test set\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "model.eval()\n",
    "preds = []\n",
    "label_list = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        input_ids, labels, lengths = data['input_ids'], data['labels'], data['lengths']\n",
    "        logits, loss = model(input_ids, labels)\n",
    "        predictions = torch.argmax(logits, dim=2)\n",
    "\n",
    "        for pred, label, length in zip(predictions.tolist(), labels.tolist(), lengths):\n",
    "            decoded_label = [idx2tag[l] for l in label]\n",
    "            label_list.extend([decoded_label[:length]])\n",
    "            trimmed_pred = pred[:length]\n",
    "            decoded_pred = [idx2tag[p] for p in trimmed_pred]\n",
    "            preds.extend([decoded_pred])\n",
    "\n",
    "flat_preds = list(itertools.chain(*preds))\n",
    "flat_labels = list(itertools.chain(*label_list))\n",
    "precision, recall, f1 = evaluate(flat_labels, flat_preds)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "fd1kB6FlcAad",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What are the precision, recall, and F1 score on the test data?.\n",
    "# precision:  74.46%; recall:  65.67%; FB1:  69.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3sF_Me3AvBF"
   },
   "source": [
    "**Task 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "taEHKhf6n_Pz",
    "outputId": "b3baf30b-a4fb-4922-a73c-410efc0efb94",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400002\n",
      "400002\n"
     ]
    }
   ],
   "source": [
    "vocab, embeddings = [], []\n",
    "with open('glove.6B.100d.txt', 'rt', encoding='utf-8') as fi:\n",
    "    full_content = fi.read().strip().split('\\n')\n",
    "\n",
    "for line in full_content:\n",
    "    parts = line.split(' ')\n",
    "    word = parts[0]\n",
    "    embedding = [float(val) for val in parts[1:]]\n",
    "    vocab.append(word)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "vocab = ['[PAD]', '[UNK]'] + vocab\n",
    "pad_emb_npa = np.zeros((1, 100))  # embedding for '<pad>' token\n",
    "unk_emb_npa = np.mean(embeddings, axis=0, keepdims=True)  # embedding for '<unk>' token\n",
    "\n",
    "# Insert embeddings for pad and unk tokens at the top of embs_npa.\n",
    "embs_npa = np.vstack((pad_emb_npa, unk_emb_npa, embeddings))\n",
    "\n",
    "vocab_npa = np.array(vocab)\n",
    "embs_npa = np.array(embs_npa)\n",
    "\n",
    "print(len(embs_npa))\n",
    "print(len(vocab_npa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "rhYXHGuvxERr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab_npa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WiC5sqrCyqfc",
    "outputId": "bb8a5236-b0bd-40d3-a02f-726afc3e7545",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[PAD]', '[UNK]', 'the', ..., 'rolonda', 'zsombor', 'sandberger'],\n",
       "      dtype='<U68')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_npa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Bfg0-JwFPQj8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_glove = datasets.load_dataset(\"conll2003\")\n",
    "\n",
    "word_frequency = Counter()\n",
    "\n",
    "word2idx_glove = {\n",
    "    word: index\n",
    "    for index, word in enumerate(vocab_npa)\n",
    "}\n",
    "\n",
    "# Iterating the dataset to replace unknown tokens with [UNK]\n",
    "dataset_glove = (\n",
    "    dataset_glove\n",
    "    .map(lambda x: {\n",
    "            'input_ids': [\n",
    "                word2idx_glove.get(word.lower(), word2idx_glove['[UNK]'])\n",
    "                for word in x['tokens']\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Removing columns pos_tags & chunk_tags; Renaming column ner_tags to labels\n",
    "for split in dataset_glove.keys():\n",
    "    dataset_glove[split] = dataset_glove[split].remove_columns(['pos_tags', 'chunk_tags'])\n",
    "    dataset_glove[split] = dataset_glove[split].rename_column('ner_tags', 'labels')\n",
    "\n",
    "train_data = dataset_glove['train']\n",
    "validation_data = dataset_glove['validation']\n",
    "test_data = dataset_glove['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "sNhjLo-wBoHr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "class BiLSTMGlove(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, lstm_hidden_dim, output_dim):\n",
    "        super(BiLSTMGlove, self).__init__()\n",
    "        droupout_val = 0.33\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(embs_npa).float(), freeze=True)\n",
    "        self.upper_embedding = nn.Embedding(2,10)\n",
    "        self.lower_embedding = nn.Embedding(2,10)\n",
    "        self.title_embedding = nn.Embedding(2,10)\n",
    "\n",
    "        self.bilstm = nn.LSTM(embedding_dim+30, lstm_hidden_dim, num_layers = 1, bidirectional=True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(droupout_val)\n",
    "        self.linear = nn.Linear(lstm_hidden_dim*2, output_dim)\n",
    "        self.elu = nn.ELU()\n",
    "        self.classifier = nn.Linear(output_dim, len(ner_tags)-1)\n",
    "\n",
    "    def forward(self, x, is_upper, lower_case, title_case, labels=None):\n",
    "        embed = self.embedding(x)\n",
    "        upper = self.upper_embedding(is_upper)\n",
    "        lower = self.lower_embedding(lower_case)\n",
    "        title = self.lower_embedding(title_case)\n",
    "        features = torch.cat((embed, upper, lower, title), dim=-1)\n",
    "        lstm_out, _ = self.bilstm(features)\n",
    "        drop = self.dropout(lstm_out)\n",
    "        linear = self.linear(drop)\n",
    "        elu_out = self.elu(linear)\n",
    "        logits = self.classifier(elu_out)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            logits_flatten = logits.view(-1, logits.shape[-1])\n",
    "            labels_flatten = labels.view(-1)\n",
    "            loss = nn.functional.cross_entropy(logits_flatten, labels_flatten,ignore_index=9)\n",
    "\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "NbtcV7G3CK8Z",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def collate_fun_glove(batch):\n",
    "\n",
    "    input_ids = [torch.tensor(item['input_ids'], device=device) for item in batch]\n",
    "    labels = [torch.tensor(item['labels'], device=device) for item in batch]\n",
    "    lengths = [len(label) for label in labels]\n",
    "\n",
    "    # Additional features\n",
    "    upper_case = [torch.tensor([1 if word.isupper() else 0 for word in item['tokens']], dtype=torch.long,device=device) for item in batch]\n",
    "    lower_case = [torch.tensor([1 if word.islower() else 0 for word in item['tokens']], dtype=torch.long,device=device) for item in batch]\n",
    "    title_case = [torch.tensor([1 if word.istitle() else 0 for word in item['tokens']], dtype=torch.long,device=device) for item in batch]\n",
    "\n",
    "    upper_case_padded = torch.nn.utils.rnn.pad_sequence(upper_case, batch_first=True, padding_value=0)\n",
    "    lower_case_padded = torch.nn.utils.rnn.pad_sequence(lower_case, batch_first=True, padding_value=0)\n",
    "    title_case_padded = torch.nn.utils.rnn.pad_sequence(title_case, batch_first=True, padding_value=0)\n",
    "\n",
    "    input_ids_padded = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "    labels_padded = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=9)\n",
    "\n",
    "    return {'input_ids': input_ids_padded, 'labels': labels_padded, 'lengths': lengths, 'upper_case': upper_case_padded, 'lower_case': lower_case_padded,\n",
    "            'title_case': title_case_padded}\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size= batch_size, collate_fn = collate_fun_glove)\n",
    "test_loader = DataLoader(test_data, batch_size= batch_size, collate_fn = collate_fun_glove)\n",
    "validation_loader = DataLoader(validation_data, batch_size= batch_size, collate_fn = collate_fun_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "GCViXPUhDDqU",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_glove = BiLSTMGlove(vocab_size=vocab_size, embedding_dim=100, lstm_hidden_dim=256, output_dim=128).to(device)\n",
    "optimizer = AdamW(model_glove.parameters(),lr=0.001)\n",
    "best_val_f1 = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86rPyRn7DLf4",
    "outputId": "b7b8dee8-7935-412a-c3e9-a30385a95809",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51362 tokens with 5942 phrases; found: 6050 phrases; correct: 4851.\n",
      "accuracy:  82.66%; (non-O)\n",
      "accuracy:  96.85%; precision:  80.18%; recall:  81.64%; FB1:  80.90\n",
      "              LOC: precision:  84.45%; recall:  86.34%; FB1:  85.38  1878\n",
      "             MISC: precision:  69.18%; recall:  71.58%; FB1:  70.36  954\n",
      "              ORG: precision:  67.93%; recall:  68.38%; FB1:  68.15  1350\n",
      "              PER: precision:  90.36%; recall:  91.64%; FB1:  91.00  1868\n",
      "Epoch: 0, Train Loss: 0.2715232573366875\n",
      "Epoch: 0, Validation Loss: 0.10504391064922161\n",
      "Validation F1 increased (0.0000 --> 80.9039). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 6041 phrases; correct: 5154.\n",
      "accuracy:  87.25%; (non-O)\n",
      "accuracy:  97.67%; precision:  85.32%; recall:  86.74%; FB1:  86.02\n",
      "              LOC: precision:  88.01%; recall:  93.47%; FB1:  90.65  1951\n",
      "             MISC: precision:  73.92%; recall:  79.93%; FB1:  76.81  997\n",
      "              ORG: precision:  78.57%; recall:  74.65%; FB1:  76.56  1274\n",
      "              PER: precision:  93.40%; recall:  92.24%; FB1:  92.82  1819\n",
      "Epoch: 1, Train Loss: 0.10237841387167955\n",
      "Epoch: 1, Validation Loss: 0.0793897450203076\n",
      "Validation F1 increased (80.9039 --> 86.0219). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 6019 phrases; correct: 5289.\n",
      "accuracy:  89.52%; (non-O)\n",
      "accuracy:  98.07%; precision:  87.87%; recall:  89.01%; FB1:  88.44\n",
      "              LOC: precision:  91.47%; recall:  94.56%; FB1:  92.99  1899\n",
      "             MISC: precision:  78.32%; recall:  81.89%; FB1:  80.06  964\n",
      "              ORG: precision:  81.30%; recall:  79.42%; FB1:  80.35  1310\n",
      "              PER: precision:  93.82%; recall:  94.03%; FB1:  93.93  1846\n",
      "Epoch: 2, Train Loss: 0.07497241848375402\n",
      "Epoch: 2, Validation Loss: 0.06275374148732654\n",
      "Validation F1 increased (86.0219 --> 88.4374). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 5998 phrases; correct: 5346.\n",
      "accuracy:  90.51%; (non-O)\n",
      "accuracy:  98.24%; precision:  89.13%; recall:  89.97%; FB1:  89.55\n",
      "              LOC: precision:  92.51%; recall:  94.77%; FB1:  93.63  1882\n",
      "             MISC: precision:  78.78%; recall:  84.16%; FB1:  81.38  985\n",
      "              ORG: precision:  84.91%; recall:  80.98%; FB1:  82.90  1279\n",
      "              PER: precision:  94.11%; recall:  94.63%; FB1:  94.37  1852\n",
      "Epoch: 3, Train Loss: 0.05710048237067683\n",
      "Epoch: 3, Validation Loss: 0.057212442708630844\n",
      "Validation F1 increased (88.4374 --> 89.5477). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 5986 phrases; correct: 5379.\n",
      "accuracy:  91.22%; (non-O)\n",
      "accuracy:  98.36%; precision:  89.86%; recall:  90.53%; FB1:  90.19\n",
      "              LOC: precision:  94.23%; recall:  94.28%; FB1:  94.26  1838\n",
      "             MISC: precision:  80.39%; recall:  84.92%; FB1:  82.59  974\n",
      "              ORG: precision:  84.06%; recall:  83.37%; FB1:  83.71  1330\n",
      "              PER: precision:  94.69%; recall:  94.79%; FB1:  94.74  1844\n",
      "Epoch: 4, Train Loss: 0.0450371005955568\n",
      "Epoch: 4, Validation Loss: 0.05253829852867342\n",
      "Validation F1 increased (89.5477 --> 90.1911). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 6022 phrases; correct: 5426.\n",
      "accuracy:  91.70%; (non-O)\n",
      "accuracy:  98.41%; precision:  90.10%; recall:  91.32%; FB1:  90.71\n",
      "              LOC: precision:  94.28%; recall:  95.05%; FB1:  94.66  1852\n",
      "             MISC: precision:  79.76%; recall:  85.90%; FB1:  82.72  993\n",
      "              ORG: precision:  85.34%; recall:  84.19%; FB1:  84.76  1323\n",
      "              PER: precision:  94.88%; recall:  95.49%; FB1:  95.18  1854\n",
      "Epoch: 5, Train Loss: 0.03613554203625188\n",
      "Epoch: 5, Validation Loss: 0.05176268622973094\n",
      "Validation F1 increased (90.1911 --> 90.7054). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 5998 phrases; correct: 5446.\n",
      "accuracy:  92.12%; (non-O)\n",
      "accuracy:  98.49%; precision:  90.80%; recall:  91.65%; FB1:  91.22\n",
      "              LOC: precision:  94.33%; recall:  95.10%; FB1:  94.71  1852\n",
      "             MISC: precision:  82.51%; recall:  85.47%; FB1:  83.96  955\n",
      "              ORG: precision:  86.22%; recall:  85.38%; FB1:  85.80  1328\n",
      "              PER: precision:  94.79%; recall:  95.87%; FB1:  95.33  1863\n",
      "Epoch: 6, Train Loss: 0.02866752836070313\n",
      "Epoch: 6, Validation Loss: 0.05244049765086874\n",
      "Validation F1 increased (90.7054 --> 91.2228). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 5985 phrases; correct: 5451.\n",
      "accuracy:  92.37%; (non-O)\n",
      "accuracy:  98.53%; precision:  91.08%; recall:  91.74%; FB1:  91.41\n",
      "              LOC: precision:  94.70%; recall:  95.26%; FB1:  94.98  1848\n",
      "             MISC: precision:  81.22%; recall:  85.36%; FB1:  83.24  969\n",
      "              ORG: precision:  87.42%; recall:  86.06%; FB1:  86.73  1320\n",
      "              PER: precision:  95.24%; recall:  95.55%; FB1:  95.39  1848\n",
      "Epoch: 7, Train Loss: 0.022723367547240865\n",
      "Epoch: 7, Validation Loss: 0.05320340288502242\n",
      "Validation F1 increased (91.2228 --> 91.4061). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 6043 phrases; correct: 5473.\n",
      "accuracy:  92.37%; (non-O)\n",
      "accuracy:  98.50%; precision:  90.57%; recall:  92.11%; FB1:  91.33\n",
      "              LOC: precision:  93.81%; recall:  95.75%; FB1:  94.77  1875\n",
      "             MISC: precision:  79.62%; recall:  86.88%; FB1:  83.09  1006\n",
      "              ORG: precision:  87.01%; recall:  85.91%; FB1:  86.45  1324\n",
      "              PER: precision:  95.81%; recall:  95.60%; FB1:  95.71  1838\n",
      "Epoch: 8, Train Loss: 0.018257219020112615\n",
      "Epoch: 8, Validation Loss: 0.057465917216819325\n",
      "processed 51362 tokens with 5942 phrases; found: 5972 phrases; correct: 5428.\n",
      "accuracy:  91.61%; (non-O)\n",
      "accuracy:  98.42%; precision:  90.89%; recall:  91.35%; FB1:  91.12\n",
      "              LOC: precision:  94.73%; recall:  94.83%; FB1:  94.78  1839\n",
      "             MISC: precision:  79.84%; recall:  85.47%; FB1:  82.56  987\n",
      "              ORG: precision:  87.48%; recall:  85.46%; FB1:  86.46  1310\n",
      "              PER: precision:  95.42%; recall:  95.11%; FB1:  95.27  1836\n",
      "Epoch: 9, Train Loss: 0.014468162008682514\n",
      "Epoch: 9, Validation Loss: 0.06627412902682908\n",
      "processed 51362 tokens with 5942 phrases; found: 6046 phrases; correct: 5454.\n",
      "accuracy:  91.78%; (non-O)\n",
      "accuracy:  98.43%; precision:  90.21%; recall:  91.79%; FB1:  90.99\n",
      "              LOC: precision:  92.87%; recall:  96.46%; FB1:  94.63  1908\n",
      "             MISC: precision:  79.38%; recall:  86.01%; FB1:  82.56  999\n",
      "              ORG: precision:  87.62%; recall:  84.41%; FB1:  85.99  1292\n",
      "              PER: precision:  95.13%; recall:  95.39%; FB1:  95.26  1847\n",
      "Epoch: 10, Train Loss: 0.012428276478133332\n",
      "Epoch: 10, Validation Loss: 0.07182222778490041\n",
      "processed 51362 tokens with 5942 phrases; found: 6055 phrases; correct: 5466.\n",
      "accuracy:  92.39%; (non-O)\n",
      "accuracy:  98.46%; precision:  90.27%; recall:  91.99%; FB1:  91.12\n",
      "              LOC: precision:  93.03%; recall:  95.97%; FB1:  94.48  1895\n",
      "             MISC: precision:  81.75%; recall:  86.01%; FB1:  83.83  970\n",
      "              ORG: precision:  86.09%; recall:  86.28%; FB1:  86.18  1344\n",
      "              PER: precision:  94.96%; recall:  95.17%; FB1:  95.07  1846\n",
      "Epoch: 11, Train Loss: 0.010326147472391238\n",
      "Epoch: 11, Validation Loss: 0.06595770871047303\n",
      "processed 51362 tokens with 5942 phrases; found: 6060 phrases; correct: 5489.\n",
      "accuracy:  92.74%; (non-O)\n",
      "accuracy:  98.53%; precision:  90.58%; recall:  92.38%; FB1:  91.47\n",
      "              LOC: precision:  92.31%; recall:  96.73%; FB1:  94.47  1925\n",
      "             MISC: precision:  83.42%; recall:  86.23%; FB1:  84.80  953\n",
      "              ORG: precision:  87.52%; recall:  85.76%; FB1:  86.63  1314\n",
      "              PER: precision:  94.59%; recall:  95.93%; FB1:  95.26  1868\n",
      "Epoch: 12, Train Loss: 0.00924966951802193\n",
      "Epoch: 12, Validation Loss: 0.07136137768559944\n",
      "Validation F1 increased (91.4061 --> 91.4681). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 6005 phrases; correct: 5481.\n",
      "accuracy:  92.74%; (non-O)\n",
      "accuracy:  98.57%; precision:  91.27%; recall:  92.24%; FB1:  91.76\n",
      "              LOC: precision:  94.71%; recall:  95.48%; FB1:  95.09  1852\n",
      "             MISC: precision:  83.48%; recall:  84.38%; FB1:  83.93  932\n",
      "              ORG: precision:  87.34%; recall:  89.04%; FB1:  88.18  1367\n",
      "              PER: precision:  94.66%; recall:  95.28%; FB1:  94.97  1854\n",
      "Epoch: 13, Train Loss: 0.0074038172105146734\n",
      "Epoch: 13, Validation Loss: 0.06954462036934413\n",
      "Validation F1 increased (91.4681 --> 91.7553). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 6072 phrases; correct: 5521.\n",
      "accuracy:  93.49%; (non-O)\n",
      "accuracy:  98.63%; precision:  90.93%; recall:  92.91%; FB1:  91.91\n",
      "              LOC: precision:  94.69%; recall:  96.19%; FB1:  95.44  1866\n",
      "             MISC: precision:  84.18%; recall:  86.01%; FB1:  85.09  942\n",
      "              ORG: precision:  84.72%; recall:  89.34%; FB1:  86.97  1414\n",
      "              PER: precision:  95.30%; recall:  95.71%; FB1:  95.50  1850\n",
      "Epoch: 14, Train Loss: 0.006931918180019451\n",
      "Epoch: 14, Validation Loss: 0.06828830824260386\n",
      "Validation F1 increased (91.7553 --> 91.9094). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 6034 phrases; correct: 5489.\n",
      "accuracy:  92.85%; (non-O)\n",
      "accuracy:  98.61%; precision:  90.97%; recall:  92.38%; FB1:  91.67\n",
      "              LOC: precision:  95.73%; recall:  95.10%; FB1:  95.41  1825\n",
      "             MISC: precision:  82.03%; recall:  85.14%; FB1:  83.56  957\n",
      "              ORG: precision:  85.43%; recall:  90.08%; FB1:  87.70  1414\n",
      "              PER: precision:  95.16%; recall:  94.95%; FB1:  95.05  1838\n",
      "Epoch: 15, Train Loss: 0.006898024848981494\n",
      "Epoch: 15, Validation Loss: 0.07125043617563778\n",
      "processed 51362 tokens with 5942 phrases; found: 6074 phrases; correct: 5497.\n",
      "accuracy:  93.13%; (non-O)\n",
      "accuracy:  98.53%; precision:  90.50%; recall:  92.51%; FB1:  91.49\n",
      "              LOC: precision:  96.14%; recall:  94.83%; FB1:  95.48  1812\n",
      "             MISC: precision:  79.86%; recall:  86.01%; FB1:  82.82  993\n",
      "              ORG: precision:  84.56%; recall:  88.59%; FB1:  86.53  1405\n",
      "              PER: precision:  95.17%; recall:  96.31%; FB1:  95.74  1864\n",
      "Epoch: 16, Train Loss: 0.007662423328580554\n",
      "Epoch: 16, Validation Loss: 0.0708807601856154\n",
      "processed 51362 tokens with 5942 phrases; found: 6046 phrases; correct: 5515.\n",
      "accuracy:  93.39%; (non-O)\n",
      "accuracy:  98.64%; precision:  91.22%; recall:  92.81%; FB1:  92.01\n",
      "              LOC: precision:  95.42%; recall:  95.37%; FB1:  95.40  1836\n",
      "             MISC: precision:  83.88%; recall:  85.79%; FB1:  84.83  943\n",
      "              ORG: precision:  85.74%; recall:  89.71%; FB1:  87.68  1403\n",
      "              PER: precision:  94.90%; recall:  96.04%; FB1:  95.47  1864\n",
      "Epoch: 17, Train Loss: 0.00511772343176702\n",
      "Epoch: 17, Validation Loss: 0.06980832576995427\n",
      "Validation F1 increased (91.9094 --> 92.0087). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 6065 phrases; correct: 5500.\n",
      "accuracy:  93.01%; (non-O)\n",
      "accuracy:  98.55%; precision:  90.68%; recall:  92.56%; FB1:  91.61\n",
      "              LOC: precision:  93.54%; recall:  96.90%; FB1:  95.19  1903\n",
      "             MISC: precision:  81.58%; recall:  86.44%; FB1:  83.94  977\n",
      "              ORG: precision:  87.86%; recall:  86.35%; FB1:  87.10  1318\n",
      "              PER: precision:  94.54%; recall:  95.82%; FB1:  95.17  1867\n",
      "Epoch: 18, Train Loss: 0.005656444585575619\n",
      "Epoch: 18, Validation Loss: 0.08005778727617469\n",
      "processed 51362 tokens with 5942 phrases; found: 6077 phrases; correct: 5546.\n",
      "accuracy:  93.77%; (non-O)\n",
      "accuracy:  98.70%; precision:  91.26%; recall:  93.34%; FB1:  92.29\n",
      "              LOC: precision:  94.15%; recall:  96.35%; FB1:  95.24  1880\n",
      "             MISC: precision:  84.65%; recall:  86.12%; FB1:  85.38  938\n",
      "              ORG: precision:  86.91%; recall:  90.08%; FB1:  88.47  1390\n",
      "              PER: precision:  94.92%; recall:  96.31%; FB1:  95.61  1869\n",
      "Epoch: 19, Train Loss: 0.004142424101014657\n",
      "Epoch: 19, Validation Loss: 0.07158923786378003\n",
      "Validation F1 increased (92.0087 --> 92.2872). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 6071 phrases; correct: 5528.\n",
      "accuracy:  93.58%; (non-O)\n",
      "accuracy:  98.66%; precision:  91.06%; recall:  93.03%; FB1:  92.03\n",
      "              LOC: precision:  94.84%; recall:  96.03%; FB1:  95.43  1860\n",
      "             MISC: precision:  85.43%; recall:  85.25%; FB1:  85.34  920\n",
      "              ORG: precision:  85.37%; recall:  89.63%; FB1:  87.45  1408\n",
      "              PER: precision:  94.32%; recall:  96.42%; FB1:  95.36  1883\n",
      "Epoch: 20, Train Loss: 0.0035400247416768355\n",
      "Epoch: 20, Validation Loss: 0.07703571870804557\n",
      "processed 51362 tokens with 5942 phrases; found: 6089 phrases; correct: 5525.\n",
      "accuracy:  93.56%; (non-O)\n",
      "accuracy:  98.64%; precision:  90.74%; recall:  92.98%; FB1:  91.85\n",
      "              LOC: precision:  95.24%; recall:  94.77%; FB1:  95.01  1828\n",
      "             MISC: precision:  83.83%; recall:  86.01%; FB1:  84.90  946\n",
      "              ORG: precision:  84.55%; recall:  90.98%; FB1:  87.64  1443\n",
      "              PER: precision:  94.60%; recall:  96.15%; FB1:  95.37  1872\n",
      "Epoch: 21, Train Loss: 0.003488394026173085\n",
      "Epoch: 21, Validation Loss: 0.0817668135392054\n",
      "processed 51362 tokens with 5942 phrases; found: 6051 phrases; correct: 5527.\n",
      "accuracy:  93.54%; (non-O)\n",
      "accuracy:  98.70%; precision:  91.34%; recall:  93.02%; FB1:  92.17\n",
      "              LOC: precision:  95.02%; recall:  95.54%; FB1:  95.28  1847\n",
      "             MISC: precision:  83.57%; recall:  87.74%; FB1:  85.61  968\n",
      "              ORG: precision:  87.34%; recall:  89.04%; FB1:  88.18  1367\n",
      "              PER: precision:  94.65%; recall:  96.04%; FB1:  95.34  1869\n",
      "Epoch: 22, Train Loss: 0.0033994918974745185\n",
      "Epoch: 22, Validation Loss: 0.08185144328134873\n",
      "processed 51362 tokens with 5942 phrases; found: 6092 phrases; correct: 5512.\n",
      "accuracy:  93.29%; (non-O)\n",
      "accuracy:  98.55%; precision:  90.48%; recall:  92.76%; FB1:  91.61\n",
      "              LOC: precision:  95.08%; recall:  94.77%; FB1:  94.93  1831\n",
      "             MISC: precision:  80.16%; recall:  87.64%; FB1:  83.73  1008\n",
      "              ORG: precision:  85.53%; recall:  89.49%; FB1:  87.46  1403\n",
      "              PER: precision:  95.30%; recall:  95.71%; FB1:  95.50  1850\n",
      "Epoch: 23, Train Loss: 0.0033876888932041797\n",
      "Epoch: 23, Validation Loss: 0.08728449949725953\n",
      "processed 51362 tokens with 5942 phrases; found: 6038 phrases; correct: 5509.\n",
      "accuracy:  93.28%; (non-O)\n",
      "accuracy:  98.65%; precision:  91.24%; recall:  92.71%; FB1:  91.97\n",
      "              LOC: precision:  94.61%; recall:  95.59%; FB1:  95.10  1856\n",
      "             MISC: precision:  83.40%; recall:  84.49%; FB1:  83.94  934\n",
      "              ORG: precision:  86.38%; recall:  90.83%; FB1:  88.55  1410\n",
      "              PER: precision:  95.54%; recall:  95.33%; FB1:  95.43  1838\n",
      "Epoch: 24, Train Loss: 0.0032230220378077516\n",
      "Epoch: 24, Validation Loss: 0.08627318399033744\n",
      "processed 51362 tokens with 5942 phrases; found: 6053 phrases; correct: 5554.\n",
      "accuracy:  93.82%; (non-O)\n",
      "accuracy:  98.73%; precision:  91.76%; recall:  93.47%; FB1:  92.61\n",
      "              LOC: precision:  95.44%; recall:  95.70%; FB1:  95.57  1842\n",
      "             MISC: precision:  85.04%; recall:  85.68%; FB1:  85.36  929\n",
      "              ORG: precision:  86.46%; recall:  91.42%; FB1:  88.87  1418\n",
      "              PER: precision:  95.49%; recall:  96.63%; FB1:  96.06  1864\n",
      "Epoch: 25, Train Loss: 0.0038534758859634544\n",
      "Epoch: 25, Validation Loss: 0.08241541978256378\n",
      "Validation F1 increased (92.2872 --> 92.6053). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 6012 phrases; correct: 5524.\n",
      "accuracy:  93.35%; (non-O)\n",
      "accuracy:  98.71%; precision:  91.88%; recall:  92.97%; FB1:  92.42\n",
      "              LOC: precision:  95.38%; recall:  95.43%; FB1:  95.40  1838\n",
      "             MISC: precision:  84.62%; recall:  85.90%; FB1:  85.25  936\n",
      "              ORG: precision:  87.87%; recall:  90.75%; FB1:  89.29  1385\n",
      "              PER: precision:  95.09%; recall:  95.66%; FB1:  95.37  1853\n",
      "Epoch: 26, Train Loss: 0.002702540738231117\n",
      "Epoch: 26, Validation Loss: 0.08476743231450364\n",
      "processed 51362 tokens with 5942 phrases; found: 6003 phrases; correct: 5537.\n",
      "accuracy:  93.53%; (non-O)\n",
      "accuracy:  98.73%; precision:  92.24%; recall:  93.18%; FB1:  92.71\n",
      "              LOC: precision:  94.52%; recall:  96.62%; FB1:  95.56  1878\n",
      "             MISC: precision:  86.99%; recall:  84.82%; FB1:  85.89  899\n",
      "              ORG: precision:  88.06%; recall:  90.16%; FB1:  89.09  1373\n",
      "              PER: precision:  95.57%; recall:  96.15%; FB1:  95.86  1853\n",
      "Epoch: 27, Train Loss: 0.0023310799705559284\n",
      "Epoch: 27, Validation Loss: 0.08612175240561767\n",
      "Validation F1 increased (92.6053 --> 92.7082). Saving model...\n",
      "processed 51362 tokens with 5942 phrases; found: 6014 phrases; correct: 5537.\n",
      "accuracy:  93.63%; (non-O)\n",
      "accuracy:  98.75%; precision:  92.07%; recall:  93.18%; FB1:  92.62\n",
      "              LOC: precision:  95.26%; recall:  96.35%; FB1:  95.81  1858\n",
      "             MISC: precision:  86.27%; recall:  84.49%; FB1:  85.37  903\n",
      "              ORG: precision:  86.99%; recall:  91.28%; FB1:  89.08  1407\n",
      "              PER: precision:  95.56%; recall:  95.77%; FB1:  95.66  1846\n",
      "Epoch: 28, Train Loss: 0.0022321702571345818\n",
      "Epoch: 28, Validation Loss: 0.08569300297338531\n",
      "processed 51362 tokens with 5942 phrases; found: 6023 phrases; correct: 5550.\n",
      "accuracy:  93.72%; (non-O)\n",
      "accuracy:  98.77%; precision:  92.15%; recall:  93.40%; FB1:  92.77\n",
      "              LOC: precision:  95.46%; recall:  96.08%; FB1:  95.77  1849\n",
      "             MISC: precision:  85.25%; recall:  85.25%; FB1:  85.25  922\n",
      "              ORG: precision:  88.17%; recall:  90.60%; FB1:  89.37  1378\n",
      "              PER: precision:  95.20%; recall:  96.85%; FB1:  96.02  1874\n",
      "Epoch: 29, Train Loss: 0.0019563890452288387\n",
      "Epoch: 29, Validation Loss: 0.08553200845252461\n",
      "Validation F1 increased (92.7082 --> 92.7706). Saving model...\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30  # Number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model_glove.train()\n",
    "    total_loss = 0\n",
    "    total_f1 = 0\n",
    "    for data in train_loader:\n",
    "        input_ids, labels, lengths, upper_case, lower_case, title_case = data['input_ids'], data['labels'], data['lengths'], data['upper_case'], data['lower_case'], data['title_case']\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        logits, loss = model_glove(input_ids, upper_case, lower_case, title_case, labels)\n",
    "\n",
    "        if loss is not None:\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=-1).view(-1)\n",
    "        labels_flat = labels.view(-1)\n",
    "\n",
    "    model_glove.eval()\n",
    "    valid_loss, valid_f1 = 0, 0\n",
    "    all_val_predictions, all_val_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in validation_loader:\n",
    "            input_ids, labels, lengths, upper_case, lower_case, title_case = data['input_ids'], data['labels'], data['lengths'], data['upper_case'], data['lower_case'], data['title_case']\n",
    "            logits, loss = model_glove(input_ids,  upper_case,  lower_case, title_case, labels)\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            val_predictions = torch.argmax(logits, dim=-1).tolist()\n",
    "\n",
    "            for i, length in enumerate(lengths):\n",
    "                seq_preds = val_predictions[i][:length]\n",
    "                seq_labels = labels[i, :length].tolist()\n",
    "                mapped_seq_preds = [idx2tag[p] for p in seq_preds]\n",
    "                mapped_seq_labels = [idx2tag[l] for l in seq_labels]\n",
    "\n",
    "                all_val_predictions.extend(mapped_seq_preds)\n",
    "                all_val_labels.extend(mapped_seq_labels)\n",
    "\n",
    "        flat_preds = list(itertools.chain(*all_val_predictions))\n",
    "        flat_labels = list(itertools.chain(*all_val_labels))\n",
    "        precision, recall, f1 = evaluate(all_val_labels, all_val_predictions)\n",
    "\n",
    "\n",
    "        print(f\"Epoch: {epoch}, Train Loss: {total_loss / len(train_loader)}\")\n",
    "        print(f\"Epoch: {epoch}, Validation Loss: {valid_loss / len(validation_loader)}\")\n",
    "\n",
    "        if f1 > best_val_f1:\n",
    "            print(f'Validation F1 increased ({best_val_f1:.4f} --> {f1:.4f}). Saving model...')\n",
    "            torch.save(model_glove.state_dict(), 'model_glove.pt')\n",
    "            best_val_f1 = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KtsM3QLJcJVm",
    "outputId": "d3340ccf-213f-452a-c41a-73ce8544641c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTMGlove(\n",
      "  (embedding): Embedding(400002, 100)\n",
      "  (upper_embedding): Embedding(2, 10)\n",
      "  (lower_embedding): Embedding(2, 10)\n",
      "  (title_embedding): Embedding(2, 10)\n",
      "  (bilstm): LSTM(130, 256, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.33, inplace=False)\n",
      "  (linear): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (elu): ELU(alpha=1.0)\n",
      "  (classifier): Linear(in_features=128, out_features=9, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model Architecture:\n",
    "print(model_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrmKgb_-Z-gX"
   },
   "source": [
    "Hyperparameters\n",
    "\n",
    "1) Number Of Epochs: 30\n",
    "\n",
    "2) Optimizer: AdamW\n",
    "\n",
    "3) Learning rate: 0.001\n",
    "\n",
    "4) Best Model saved based on F1 score\n",
    "\n",
    "5) Dropout: 0.33\n",
    "\n",
    "6) Vocab size: 23625\n",
    "\n",
    "7) Additional features used: isUpper, isTitle, isLower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bu-HFdZdW_07"
   },
   "source": [
    "Model with Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xccTKOhXPyRY",
    "outputId": "116b3ffa-3520-4c7d-9460-d3c512007968",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51362 tokens with 5942 phrases; found: 6023 phrases; correct: 5550.\n",
      "accuracy:  93.72%; (non-O)\n",
      "accuracy:  98.77%; precision:  92.15%; recall:  93.40%; FB1:  92.77\n",
      "              LOC: precision:  95.46%; recall:  96.08%; FB1:  95.77  1849\n",
      "             MISC: precision:  85.25%; recall:  85.25%; FB1:  85.25  922\n",
      "              ORG: precision:  88.17%; recall:  90.60%; FB1:  89.37  1378\n",
      "              PER: precision:  95.20%; recall:  96.85%; FB1:  96.02  1874\n",
      "Precision: 92.14677071226963\n",
      "Recall: 93.40289464826658\n",
      "F1 Score: 92.77058086084413\n"
     ]
    }
   ],
   "source": [
    "# Model on validation set\n",
    "model_glove.load_state_dict(torch.load('model_glove.pt'))\n",
    "model_glove.eval()\n",
    "preds = []\n",
    "label_list = []\n",
    "with torch.no_grad():\n",
    "    for data in validation_loader:\n",
    "        input_ids, labels, lengths, upper_case, lower_case, title_case = data['input_ids'], data['labels'], data['lengths'], data['upper_case'], data['lower_case'], data['title_case']\n",
    "        logits, loss = model_glove(input_ids,  upper_case,  lower_case, title_case, labels)\n",
    "        predictions = torch.argmax(logits, dim=2)\n",
    "\n",
    "        for pred, label, length in zip(predictions.tolist(), labels.tolist(), lengths):\n",
    "            decoded_label = [idx2tag[l] for l in label]\n",
    "            label_list.extend([decoded_label[:length]])\n",
    "            trimmed_pred = pred[:length]\n",
    "            decoded_pred = [idx2tag[p] for p in trimmed_pred]\n",
    "            preds.extend([decoded_pred])\n",
    "\n",
    "flat_preds = list(itertools.chain(*preds))\n",
    "flat_labels = list(itertools.chain(*label_list))\n",
    "precision, recall, f1 = evaluate(flat_labels, flat_preds)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "6oU6lIV3cXH2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What are the precision, recall, and F1 score on the validation data?.\n",
    "# 98.77%; precision:  92.15%; recall:  93.40%; FB1:  92.77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edR0YOMuXzjZ"
   },
   "source": [
    "Model with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mm_epYGiXINP",
    "outputId": "4a0a8cc2-0567-4c00-b190-d668d830bf36",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 46435 tokens with 5648 phrases; found: 5785 phrases; correct: 5045.\n",
      "accuracy:  90.62%; (non-O)\n",
      "accuracy:  97.70%; precision:  87.21%; recall:  89.32%; FB1:  88.25\n",
      "              LOC: precision:  89.53%; recall:  92.75%; FB1:  91.11  1728\n",
      "             MISC: precision:  72.11%; recall:  77.35%; FB1:  74.64  753\n",
      "              ORG: precision:  84.44%; recall:  86.57%; FB1:  85.49  1703\n",
      "              PER: precision:  94.75%; recall:  93.82%; FB1:  94.28  1601\n",
      "Precision: 87.20829732065687\n",
      "Recall: 89.32365439093485\n",
      "F1 Score: 88.25330184553486\n"
     ]
    }
   ],
   "source": [
    "# Model on test set\n",
    "model_glove.load_state_dict(torch.load('model_glove.pt',map_location=torch.device(device)))\n",
    "model_glove.eval()\n",
    "preds = []\n",
    "label_list = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        input_ids, labels, lengths, upper_case, lower_case, title_case = data['input_ids'], data['labels'], data['lengths'], data['upper_case'], data['lower_case'], data['title_case']\n",
    "        logits, loss = model_glove(input_ids,  upper_case,  lower_case, title_case, labels)\n",
    "        predictions = torch.argmax(logits, dim=2)\n",
    "\n",
    "        for pred, label, length in zip(predictions.tolist(), labels.tolist(), lengths):\n",
    "            decoded_label = [idx2tag[l] for l in label]\n",
    "            label_list.extend([decoded_label[:length]])\n",
    "            trimmed_pred = pred[:length]\n",
    "            decoded_pred = [idx2tag[p] for p in trimmed_pred]\n",
    "            preds.extend([decoded_pred])\n",
    "\n",
    "flat_preds = list(itertools.chain(*preds))\n",
    "flat_labels = list(itertools.chain(*label_list))\n",
    "precision, recall, f1 = evaluate(flat_labels, flat_preds)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "vmwSiGYFX2jB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What are the precision, recall, and F1 score on the test data?.\n",
    "# precision:  87.21%; recall:  89.32%; FB1:  88.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMTjZ08RhUqO"
   },
   "source": [
    "BiLSTM with Glove Embeddings outperforms the model without. Can you\n",
    "provide a rationale for this?\n",
    "\n",
    "\n",
    "Glove Embedding is a pretrained word embedding. It is trained on large datasets and captures the semantic and syntactic meaning of the word. Learning word embeddings from scratch is challenging. While learning from scratch on our dataset we will face issue of sparsity on the training data. The vocabulary of our training dataset might not be rich enough. This is overcome by using Glove embeddings. Due to these reasons BiLSTM with Glove Embeddings outperforms the model without Glove Embeddings."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "10d5d9421b65412ea1312cfcea61d5d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1b27335e9d9548c88b53c22803b5652a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21032812faeb4317b18a213800270eed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22c79e18d7c74dcd8379aa5f0129bede": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3295795b0ab546c9a44ddbed27b70907": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b27335e9d9548c88b53c22803b5652a",
      "max": 3250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6a97dc65a24c4519ba1a006881c38b91",
      "value": 3250
     }
    },
    "346a5410b8c944418aa8a4b07aa7dbb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_403685c606ed427d84a673744fb2eb01",
       "IPY_MODEL_949a61f3b5894861b0551d2bed787c22",
       "IPY_MODEL_a1a094aef5b345168eeb0fa248d3e7d1"
      ],
      "layout": "IPY_MODEL_722fa30a89ab4746903a933835575d5a"
     }
    },
    "403685c606ed427d84a673744fb2eb01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf1094b3c35a48109bcae6ccb349485f",
      "placeholder": "",
      "style": "IPY_MODEL_7d80c0ba38094591b2afa75946208302",
      "value": "Map: 100%"
     }
    },
    "4b3594287e404655b6bf85435d061864": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67fca6992c864f58b7ef7bfd9b53959e",
      "placeholder": "",
      "style": "IPY_MODEL_55fcb1b0cbd04b999a25d98f9bf185da",
      "value": " 3250/3250 [00:01&lt;00:00, 1804.97 examples/s]"
     }
    },
    "4dc9b24267224f628940fbf62cb4a91b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "55fcb1b0cbd04b999a25d98f9bf185da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a5524c1d44c472184239b0ec74d69f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ceaeda57cd44bc88ed7dd3a8329b496": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6410529f8ecc4d7ab7523c4dd2d8e696",
      "placeholder": "",
      "style": "IPY_MODEL_d74fd57600da41438a2ff864c734657c",
      "value": " 14041/14041 [00:03&lt;00:00, 3832.36 examples/s]"
     }
    },
    "6410529f8ecc4d7ab7523c4dd2d8e696": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67fca6992c864f58b7ef7bfd9b53959e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "687ee4a211fb402fb18b4e595fb62ee6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a97dc65a24c4519ba1a006881c38b91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "722fa30a89ab4746903a933835575d5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77d6aead62bc48fea068aefd1df44ad6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d80c0ba38094591b2afa75946208302": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85d16c16b71342c6ac06d8105a414490": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86792eac34d24a57833702df5d7c38ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "949a61f3b5894861b0551d2bed787c22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77d6aead62bc48fea068aefd1df44ad6",
      "max": 3453,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_22c79e18d7c74dcd8379aa5f0129bede",
      "value": 3453
     }
    },
    "a1a094aef5b345168eeb0fa248d3e7d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85d16c16b71342c6ac06d8105a414490",
      "placeholder": "",
      "style": "IPY_MODEL_5a5524c1d44c472184239b0ec74d69f0",
      "value": " 3453/3453 [00:00&lt;00:00, 5408.76 examples/s]"
     }
    },
    "a99cd51a140b44a4b12504f499a613ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21032812faeb4317b18a213800270eed",
      "max": 14041,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10d5d9421b65412ea1312cfcea61d5d5",
      "value": 14041
     }
    },
    "ae685b5f2b8d4c538fba0f980ccb03de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf1094b3c35a48109bcae6ccb349485f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c26b46d9e06e48bf89ba3d41e2793051": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f3a8a0c823284a628bf7c95f857faefa",
       "IPY_MODEL_3295795b0ab546c9a44ddbed27b70907",
       "IPY_MODEL_4b3594287e404655b6bf85435d061864"
      ],
      "layout": "IPY_MODEL_d74f25d35ab442d19d86f8e231703191"
     }
    },
    "d74f25d35ab442d19d86f8e231703191": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d74fd57600da41438a2ff864c734657c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ddc86aa121554a6ebb65d638091f8ee9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df4b36222d7d424e84e9adad82b0f6ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f9aa6aa549124b5598da4fca2e798697",
       "IPY_MODEL_a99cd51a140b44a4b12504f499a613ed",
       "IPY_MODEL_5ceaeda57cd44bc88ed7dd3a8329b496"
      ],
      "layout": "IPY_MODEL_687ee4a211fb402fb18b4e595fb62ee6"
     }
    },
    "f3a8a0c823284a628bf7c95f857faefa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddc86aa121554a6ebb65d638091f8ee9",
      "placeholder": "",
      "style": "IPY_MODEL_4dc9b24267224f628940fbf62cb4a91b",
      "value": "Map: 100%"
     }
    },
    "f9aa6aa549124b5598da4fca2e798697": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae685b5f2b8d4c538fba0f980ccb03de",
      "placeholder": "",
      "style": "IPY_MODEL_86792eac34d24a57833702df5d7c38ff",
      "value": "Map: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
