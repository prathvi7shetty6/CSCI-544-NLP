{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prathvi Shetty                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3.11.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\prath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import warnings\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.tsv',on_bad_lines='skip', sep=\"\\t\",usecols=['star_rating','review_body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code uses pandas to read the csv file. The dataframe contains data from columns start_rating & review_body only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 2 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code to split convert the start_rating values to either 1 or 2. Any review that has a rating of 1,2 or 3 is set to 1 else it is set to 2\n",
    "The lambda function is used to update values in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class'] = data['star_rating'].apply(lambda x: 1 if x in [1,2,3] else 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## We form two classes and select 50000 reviews randomly from each class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get 50,000 reviews of both classes I filter out the data in a dataframe for both class 1 & 2. following this step I randomly select 50,000 reviews from each class using the sample method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data = pd.DataFrame(columns=data.columns)\n",
    "for rating in data['class'].unique():\n",
    "    class_set = data[data['class'] == rating]\n",
    "    random_sample = class_set.sample(n=50000)\n",
    "    balanced_data = pd.concat([balanced_data,random_sample]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code to find the average length of reviews in terms of character length in the dataset before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_col = balanced_data['review_body']\n",
    "\n",
    "average_before = sum(len(str(review)) for review in review_col)/len(review_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code to perfom cleaning by performing the following steps:\n",
    "1) The reviews are converted to lower case\n",
    "2) Any HTML tags are removed using regular expressions\n",
    "3) Any URLs presnt are removed using regular expression\n",
    "4) All the non alphabetical characters are removed followed by removal of any extra spaces\n",
    "5) The library contractions is used to perform contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting into lower case\n",
    "balanced_data['review_body'] = balanced_data['review_body'].str.lower()\n",
    "# Remove HTML tags\n",
    "balanced_data['review_body'] = balanced_data['review_body'].apply(lambda d: re.sub(r'<.*?>','',str(d)))\n",
    "# Remove URLs\n",
    "balanced_data['review_body'] = balanced_data['review_body'].apply(lambda d: re.sub(r'https?://\\S+www.\\S+', '', d))\n",
    "# Remove non alphabetical character\n",
    "balanced_data['review_body'] = balanced_data['review_body'].apply(lambda d: re.sub(r'[^a-zA-Z\\s]','',d))\n",
    "# Remove extra spaces\n",
    "balanced_data['review_body'] = balanced_data['review_body'].apply(lambda d: ' '.join(d.split()))\n",
    "# Perform contractions\n",
    "balanced_data['review_body'] = balanced_data['review_body'].apply(lambda d: contractions.fix(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code to find the average length of reviews in terms of character length in the dataset after data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319.57937, 303.36312\n"
     ]
    }
   ],
   "source": [
    "review_col = balanced_data['review_body']\n",
    "\n",
    "average_after = sum(len(str(review)) for review in review_col)/len(review_col)\n",
    "print(f\"{average_before}, {average_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the stop words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stopwords are removed in the below cell. The list of stopwords is retreived using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))\n",
    "balanced_data['review_body'] = balanced_data['review_body'].apply(lambda d: ' '.join([word for word in d.split() if word not in stopwords])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform lemmatization  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell performs lemmetization using NLTK's WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "balanced_data['review_body'] = balanced_data['review_body'].apply(lambda d: ' '.join([lemmatizer.lemmatize(word) for word in d.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code to find the average length of reviews in terms of character length in the dataset after preprocessing. The average value before and after preprocessing is printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303.36312, 188.80034\n"
     ]
    }
   ],
   "source": [
    "review_col = balanced_data['review_body']\n",
    "\n",
    "average_after_preprocessing = sum(len(str(review)) for review in review_col)/len(review_col)\n",
    "print(f\"{average_after}, {average_after_preprocessing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF and BoW Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Sklearn's TfidfVectorizer is used to obtain the document-term matrix of TF-IDF features that is used to train the models. TF-IDF is a numerical statistics used to evaluate the importance of a word within a documentrelative to a collection of documents\n",
    "2) Sklearn's CountVectorizer is used to obtain matrix of token counts from the collection of texts. This is used to train the models.CountVectorizer converts input data and transforms into bag of words. BOW is a technique that represents text as vector of word counts disregarding the order & context of words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X = balanced_data['review_body']\n",
    "    Y = balanced_data['class']\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_X = tfidf_vectorizer.fit_transform(X)\n",
    "    X_traintf, X_testtf, Y_traintf, Y_testtf = train_test_split(tfidf_X, Y, test_size=0.2)\n",
    "\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    bow_X = count_vectorizer.fit_transform(X)\n",
    "    X_trainbow, X_testbow, Y_trainbow, Y_testbow = train_test_split(bow_X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Using Both Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron using TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell the TFIDF features extracted in the previous step is used to train the model. The perceptron model is initialised, trained and used to make predictions. The prediction are measured using the precision, recall & F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7972; 0.7299; 0.7621\n"
     ]
    }
   ],
   "source": [
    "perceptron_tfidf = Perceptron()\n",
    "perceptron_tfidf.fit(X_traintf, Y_traintf.astype('int'))\n",
    "\n",
    "y_tf = perceptron_tfidf.predict(X_testtf)\n",
    "\n",
    "precision_tf = precision_score(Y_testtf.astype('int'), y_tf.astype('int'), average='binary')\n",
    "recall_tf = recall_score(Y_testtf.astype('int'), y_tf.astype('int'), average='binary')\n",
    "f1_tf = f1_score(Y_testtf.astype('int'), y_tf.astype('int'), average='binary')\n",
    "\n",
    "print(f\"{precision_tf :.4f}; {recall_tf:.4f}; {f1_tf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell the Bag Of Words features extracted in the previous step is used to train the model. The perceptron model is initialised, trained and used to make predictions. The prediction are measured using the precision, recall & F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prescision: 0.7804; Recall: 0.7551; F1 score: 0.7676\n"
     ]
    }
   ],
   "source": [
    "perceptron_bow = Perceptron()\n",
    "perceptron_bow.fit(X_trainbow, Y_trainbow.astype('int'))\n",
    "\n",
    "y_bow = perceptron_bow.predict(X_testbow)\n",
    "\n",
    "precision_bow = precision_score(Y_testbow.astype('int'),y_bow.astype('int'), average='binary')\n",
    "recall_bow = recall_score(Y_testbow.astype('int'),y_bow.astype('int'), average='binary')\n",
    "f1_bow = f1_score(Y_testbow.astype('int'),y_bow.astype('int'), average='binary')\n",
    "\n",
    "print(f\"Prescision: {precision_bow :.4f}; Recall: {recall_bow:.4f}; F1 score: {f1_bow:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Using Both Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM using TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell the TFIDF features extracted in the previous step is used to train the model. The SVM model is initialised, trained and used to make predictions. The prediction are measured using the precision, recall & F1 score. The Linear Support Vector Classification is used to fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prescision: 0.8253; Recall: 0.8443; F1 score: 0.8347\n"
     ]
    }
   ],
   "source": [
    "svm_model_tf = LinearSVC()\n",
    "svm_model_tf.fit(X_traintf, Y_traintf.astype('int'))\n",
    "\n",
    "\n",
    "y_tf_svm = svm_model_tf.predict(X_testtf)\n",
    "\n",
    "# Precision\n",
    "precision_tf_svm = precision_score(Y_testtf.astype('int'), y_tf_svm.astype('int'), average='binary')\n",
    "\n",
    "# Recall\n",
    "recall_tf_svm = recall_score(Y_testtf.astype('int'), y_tf_svm.astype('int'), average='binary')\n",
    "\n",
    "# F1 score\n",
    "f1_tf_svm = f1_score(Y_testtf.astype('int'), y_tf_svm.astype('int'), average='binary')\n",
    "\n",
    "print(f\"Prescision: {precision_tf_svm :.4f}; Recall: {recall_tf_svm:.4f}; F1 score: {f1_tf_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM using BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell the Bag Of Words features extracted in the previous step are used to train the model. The SVM model is initialised, trained and used to make predictions. The prediction are measured using the precision, recall & F1 score. The Linear Support Vector Classification is used to fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prescision: 0.8273; Recall: 0.7896; F1 score: 0.8080\n"
     ]
    }
   ],
   "source": [
    "svm_model_bow = LinearSVC()\n",
    "svm_model_bow.fit(X_trainbow, Y_trainbow.astype('int'))\n",
    "\n",
    "y_bow_svm = svm_model_bow.predict(X_testbow)\n",
    "\n",
    "# Precision\n",
    "precision_bow_svm = precision_score(Y_testbow.astype('int'),y_bow_svm.astype('int'), average='binary')\n",
    "\n",
    "# Recall\n",
    "recall_bow_svm = recall_score(Y_testbow.astype('int'),y_bow_svm.astype('int'), average='binary')\n",
    "\n",
    "# F1 score\n",
    "f1_bow_svm = f1_score(Y_testbow.astype('int'),y_bow_svm.astype('int'), average='binary')\n",
    "\n",
    "print(f\"Prescision: {precision_bow_svm :.4f}; Recall: {recall_bow_svm:.4f}; F1 score: {f1_bow_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Using Both Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression using TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell the TFIDF features extracted in the previous step are used to train the model. The Logistic Regression model is initialised, trained and used to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prescision: 0.8270; Recall: 0.8534; F1 score: 0.8400\n"
     ]
    }
   ],
   "source": [
    "logisctic_regression_tfidf = LogisticRegression()\n",
    "logisctic_regression_tfidf.fit(X_traintf, Y_traintf.astype('int'))\n",
    "\n",
    "y_tf_reg = logisctic_regression_tfidf.predict(X_testtf)\n",
    "\n",
    "# Precision\n",
    "precision_tf_reg = precision_score(Y_testtf.astype('int'), y_tf_reg.astype('int'), average='binary')\n",
    "\n",
    "# Recall\n",
    "recall_tf_reg = recall_score(Y_testtf.astype('int'), y_tf_reg.astype('int'), average='binary')\n",
    "\n",
    "# F1 score\n",
    "f1_tf_reg = f1_score(Y_testtf.astype('int'), y_tf_reg.astype('int'), average='binary')\n",
    "\n",
    "print(f\"Prescision: {precision_tf_reg :.4f}; Recall: {recall_tf_reg:.4f}; F1 score: {f1_tf_reg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression using BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell the Bag Of Words features extracted in the previous step are used to train the model. The Logistic Regression model is initialised, trained and used to make predictions. The prediction are measured using the precision, recall & F1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prescision: 0.8447; Recall: 0.8075; F1 score: 0.8257\n"
     ]
    }
   ],
   "source": [
    "logisctic_regression_bow = LogisticRegression(max_iter = 400)\n",
    "logisctic_regression_bow.fit(X_trainbow, Y_trainbow.astype('int'))\n",
    "\n",
    "y_bow_reg = logisctic_regression_bow.predict(X_testbow)\n",
    "\n",
    "# Precision\n",
    "precision_bow_reg = precision_score(Y_testbow.astype('int'), y_bow_reg.astype('int'), average='binary')\n",
    "\n",
    "# Recall\n",
    "recall_bow_reg = recall_score(Y_testbow.astype('int'), y_bow_reg.astype('int'), average='binary')\n",
    "\n",
    "# F1 score\n",
    "f1_bow_reg = f1_score(Y_testbow.astype('int'), y_bow_reg.astype('int'), average='binary')\n",
    "\n",
    "print(f\"Prescision: {precision_bow_reg :.4f}; Recall: {recall_bow_reg:.4f}; F1 score: {f1_bow_reg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Using Both Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell the TFIDF features extracted in the previous step are used to train the model. The Naive Bayes model is initialised, trained and used to make predictions.The Naive Bayes classifier for multinomial models is used to fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prescision: 0.7871; Recall: 0.8459; F1 score: 0.8154\n"
     ]
    }
   ],
   "source": [
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_traintf, Y_traintf.astype('int'))\n",
    "\n",
    "y_tfidf_nb = nb_tfidf.predict(X_testtf)\n",
    "\n",
    "# Precision\n",
    "precision_tfidf_nb = precision_score(Y_testtf.astype('int'), y_tfidf_nb.astype('int'), average='binary')\n",
    "\n",
    "# Recall\n",
    "recall_tfidf_nb = recall_score(Y_testtf.astype('int'), y_tfidf_nb.astype('int'), average='binary')\n",
    "\n",
    "# F!1 score\n",
    "f1_tfidf_nb = f1_score(Y_testtf.astype('int'), y_tfidf_nb.astype('int'), average='binary')\n",
    "\n",
    "print(f\"Prescision: {precision_tfidf_nb :.4f}; Recall: {recall_tfidf_nb:.4f}; F1 score: {f1_tfidf_nb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell the TFIDF features extracted in the previous step are used to train the model. The Naive Bayes model is initialised, trained and used to make predictions.The Naive Bayes classifier for multinomial models is used to fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prescision: 0.8132; Recall: 0.8597; F1 score: 0.8358\n"
     ]
    }
   ],
   "source": [
    "nb_bow = MultinomialNB()\n",
    "nb_bow.fit(X_trainbow, Y_trainbow.astype('int'))\n",
    "\n",
    "y_bow_nb = nb_tfidf.predict(X_testbow)\n",
    "\n",
    "# Precision\n",
    "precision_bow_nb = precision_score(Y_testbow.astype('int'), y_bow_nb.astype('int'), average='binary')\n",
    "\n",
    "# Recall\n",
    "recall_bow_nb = recall_score(Y_testbow.astype('int'), y_bow_nb.astype('int'), average='binary')\n",
    "\n",
    "# F1 score\n",
    "f1_bow_nb = f1_score(Y_testbow.astype('int'), y_bow_nb.astype('int'), average='binary')\n",
    "\n",
    "print(f\"Prescision: {precision_bow_nb :.4f}; Recall: {recall_bow_nb:.4f}; F1 score: {f1_bow_nb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the given dataset Perceptron model is giving me the lowest F1 scores when compared to other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
